{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basket Ball Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to perform two sets of analysis. Essentially I want to how the mnist network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import tempfile\n",
    "import cv2\n",
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.contrib.data import Dataset, Iterator\n",
    "\n",
    "%run lib/util.py # contains utilities to retrieve the data from the basketball image folder\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is essentially a dead copy of the tensor flow deep example, showing how to build a proper network. I've modified to allow it to deal with variable values from height, width and classification labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnist_network(x, height, width, num_labels):\n",
    "  \"\"\" builds the mnist neural net for analysing arbitrary dimension images\n",
    "  Args:\n",
    "    x: an input tensor with the dimensions \n",
    "    height: height of the image\n",
    "    widht: width of the image\n",
    "    \n",
    "  Returns:\n",
    "    A tuple (y, keep_prob). y is a tensor of shape (N_examples, num_labels), with values\n",
    "    equal to the logits of classifying the image into one of num_labels classes. \n",
    "    keep_prob is a scalar placeholder for the probability of\n",
    "    dropout.\n",
    "  \"\"\"\n",
    "  # Reshape to use within a convolutional neural net.\n",
    "  # Last dimension is for \"features\" - there is only one here, since images are\n",
    "  # grayscale -- it would be 3 for an RGB image, 4 for RGBA, etc.\n",
    "  with tf.name_scope('reshape'):\n",
    "    x_image = tf.reshape(x, [-1, height, width, 3])\n",
    "\n",
    "  # First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "  with tf.name_scope('conv1'):\n",
    "    W_conv1 = weight_variable([5, 5, 3, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "  # Pooling layer - downsamples by 2X.\n",
    "  with tf.name_scope('pool1'):\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "  # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "  with tf.name_scope('conv2'):\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "  # Second pooling layer.\n",
    "  with tf.name_scope('pool2'):\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "  # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n",
    "  # is down to 7x7x64 feature maps -- maps this to 1024 features.\n",
    "  with tf.name_scope('fc1'):\n",
    "    W_fc1 = weight_variable([10 * 10 * 64, 128])\n",
    "    b_fc1 = bias_variable([128])\n",
    "\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 10*10*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "  # Dropout - controls the complexity of the model, prevents co-adaptation of\n",
    "  # features.\n",
    "  with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "  # Map the features to num_labels classes\n",
    "  with tf.name_scope('fc2'):\n",
    "    W_fc2 = weight_variable([128, num_labels])\n",
    "    b_fc2 = bias_variable([num_labels])\n",
    "\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "  return y_conv, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function below from the tensor flow deep tutorial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "  \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "  \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_data(training_images, training_ground_truth, batch_size, epoch):\n",
    "    \"\"\"returns a tf data with it's iterator and initialiser for given batch size and epoch \"\"\"\n",
    "    # create TensorFlow Dataset objects\n",
    "    tr_data = Dataset.from_tensor_slices((training_images.values, training_ground_truth.values))\n",
    "    tr_data = tr_data.shuffle(buffer_size=10000)\n",
    "    tr_data = tr_data.batch(batch_size)\n",
    "    \n",
    "    # if epoch none then don't repeat at all\n",
    "    if epoch :\n",
    "        tr_data = tr_data.repeat(epoch)\n",
    "\n",
    "    # create TensorFlow Iterator object\n",
    "    iterator = Iterator.from_structure(tr_data.output_types,\n",
    "                                     tr_data.output_shapes)\n",
    "\n",
    "    next_element = iterator.get_next()\n",
    "\n",
    "    training_init_op = iterator.make_initializer(tr_data)\n",
    "    return (tr_data, next_element, training_init_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "Now the fun begins, we specify the input placeholder create the loss function and convert the data into a data frame for manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "width = 40\n",
    "height = 40\n",
    "x = tf.placeholder(tf.float32, [None, height * width * 3])\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "# Build the graph for the deep net\n",
    "y_conv, keep_prob = mnist_network(x, height, width, num_labels=2)\n",
    "y_conv_orig, keep_prob_orig = mnist_network(x, height, width, num_labels=2)\n",
    "\n",
    "prediction_ = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "# get rescaled training data and convert to data frame\n",
    "(images, ground_truth) = get_rescaled_image(40, 40)\n",
    "images_df = pd.DataFrame(data=images)\n",
    "ground_truth_df = pd.DataFrame(data=ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal amount negative and positive examples\n",
    "\n",
    "So what we need to do to test the  idea of a training set with equalish amount of samples of containing basketballs and not containing basketballs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bballs images in traing set: %d (64, 2)\n",
      "Number of neg bballs images in traing set: %d (300, 2)\n"
     ]
    }
   ],
   "source": [
    "# segregate into training and test data\n",
    "num_images = images_df.shape[0]\n",
    "train_length = int(0.8 * num_images)\n",
    "training_images = images_df[: train_length]\n",
    "training_ground_truth = ground_truth_df[: train_length]\n",
    "\n",
    "\n",
    "training_images_ad = training_images[training_ground_truth[0] == 1]\n",
    "training_ground_truth_ad = training_ground_truth[training_ground_truth[0] == 1]\n",
    "\n",
    "training_images_eq = training_images\n",
    "training_ground_truth_eq = training_ground_truth\n",
    "\n",
    "for i in range(4):\n",
    "    training_images_eq = training_images.append(training_images_ad)  \n",
    "    training_ground_truth_eq = training_ground_truth.append(training_ground_truth_ad)\n",
    "\n",
    "test_images = images_df[train_length + 1:]\n",
    "test_ground_truth = ground_truth_df[train_length + 1:]\n",
    "\n",
    "test_images = test_images[test_ground_truth[0] == 1]\n",
    "test_ground_truth = test_ground_truth[test_ground_truth[0] == 1]\n",
    "\n",
    "print(\"Number of bballs images in traing set: %d\", (training_ground_truth[training_ground_truth[0]==1].shape)) \n",
    "print(\"Number of neg bballs images in traing set: %d\", (training_ground_truth[training_ground_truth[0]==0].shape)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Data\n",
    "\n",
    "We need to shuffle data so batch training gets good mix of training instances per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph to: C:\\Users\\crisyp\\AppData\\Local\\Temp\\tmpowq3ta_x\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_,\n",
    "                                                            logits=y_conv)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "with tf.name_scope('adam_optimizer'):\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "graph_location = tempfile.mkdtemp()\n",
    "print('Saving graph to: %s' % graph_location)\n",
    "train_writer = tf.summary.FileWriter(graph_location)\n",
    "train_writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get batch data which has been enhanced by adding multiples of the same images of basketsballs to it to even representation of both classes and then the original data set which has more of a 30-70 split between basketballs and  non basketball image classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "epoch = 25\n",
    "tr_data_eq, next_element_eq, training_init_op_eq = batch_data(training_images_eq, training_ground_truth_eq, batch_size, None)\n",
    "tr_data_orig, next_element_orig, training_init_op_orig = batch_data(training_images, training_ground_truth, batch_size, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with parity data set (equalish bball and non bball classes)\n",
    "\n",
    "Train with the parity data set and accumulate learning error scores as the data size trained with increases (learning curve). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    train_error = list()\n",
    "    test_error = list()\n",
    "    batch_sizes =  list()\n",
    "    num_batches = 0\n",
    "    try:\n",
    "      sess.run(tf.global_variables_initializer())\n",
    "      sess.run(tf.local_variables_initializer())\n",
    "    except Exception as e:\n",
    "      print(\"error\")\n",
    "\n",
    "    for _ in range(epoch):\n",
    "        # initialize the iterator on the training data\n",
    "        sess.run(training_init_op_eq)\n",
    "\n",
    "        # equal amount of positive images\n",
    "        # get each element of the training dataset until the end is reached\n",
    "        while True:\n",
    "            try:\n",
    "                (image_batch, ground_truth_batch) = sess.run(next_element_eq)\n",
    "                _, loss_val = sess.run([train_step, cross_entropy],\n",
    "                                       feed_dict={x: image_batch,\n",
    "                                                  y_: ground_truth_batch, keep_prob: 0.5})\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"End of training dataset.\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"error: %s\", e)\n",
    "        train_accuracy = accuracy.eval(feed_dict={ x: image_batch,\n",
    "                                          y_: ground_truth_batch, keep_prob: 1.0})\n",
    "        test_accuracy = accuracy.eval(feed_dict={ x: test_images.values,\n",
    "                                          y_: test_ground_truth.values, keep_prob: 1.0})\n",
    "\n",
    "        num_batches = num_batches + batch_size\n",
    "        print('training accuracy %g' % train_accuracy)\n",
    "        print('test accuracy %g' % test_accuracy)\n",
    "        print('loss_val %g' % loss_val)\n",
    "        train_error.append(1-train_accuracy)\n",
    "        test_error.append(1-test_accuracy)\n",
    "        batch_sizes.append(num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with original non-parity data set (30-70 split bball and non bball classes)\n",
    "\n",
    "Train with the orignal parity data set and accumulate learning error scores as the data size trained with increases (learning curve). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of training dataset.\n",
      "training accuracy 0.5\n",
      "test accuracy 0\n",
      "loss_val 519.95\n",
      "End of training dataset.\n",
      "training accuracy 0.5\n",
      "test accuracy 0.388889\n",
      "loss_val 270.544\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.111111\n",
      "loss_val 71.7426\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.222222\n",
      "loss_val 45.8223\n",
      "End of training dataset.\n",
      "training accuracy 0.75\n",
      "test accuracy 0.222222\n",
      "loss_val 263.208\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.222222\n",
      "loss_val 3.07102\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.277778\n",
      "loss_val 0\n",
      "End of training dataset.\n",
      "training accuracy 0.25\n",
      "test accuracy 0.277778\n",
      "loss_val 66.2683\n",
      "End of training dataset.\n",
      "training accuracy 0.75\n",
      "test accuracy 0.444444\n",
      "loss_val 207.164\n",
      "End of training dataset.\n",
      "training accuracy 0.75\n",
      "test accuracy 0.5\n",
      "loss_val 56.8301\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.333333\n",
      "loss_val 0\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.333333\n",
      "loss_val 0\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.277778\n",
      "loss_val 7.15255e-07\n",
      "End of training dataset.\n",
      "training accuracy 0.75\n",
      "test accuracy 0.444444\n",
      "loss_val 0\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.388889\n",
      "loss_val 14.5204\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.388889\n",
      "loss_val 0.551821\n",
      "End of training dataset.\n",
      "training accuracy 0.75\n",
      "test accuracy 0.388889\n",
      "loss_val 3.49571\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.333333\n",
      "loss_val 0\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.5\n",
      "loss_val 0\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.388889\n",
      "loss_val 0\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.388889\n",
      "loss_val 5.36856\n",
      "End of training dataset.\n",
      "training accuracy 0.5\n",
      "test accuracy 0.277778\n",
      "loss_val 0\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.388889\n",
      "loss_val 11.5301\n",
      "End of training dataset.\n",
      "training accuracy 0.75\n",
      "test accuracy 0.333333\n",
      "loss_val 0\n",
      "End of training dataset.\n",
      "training accuracy 1\n",
      "test accuracy 0.333333\n",
      "loss_val 2.46831\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    train_error_orig = list()\n",
    "    test_error_orig = list()\n",
    "    batch_sizes_orig =  list()\n",
    "    num_batches = 0\n",
    "    try:\n",
    "      sess.run(tf.global_variables_initializer())\n",
    "      sess.run(tf.local_variables_initializer())\n",
    "    except Exception as e:\n",
    "      print(\"error\")\n",
    "\n",
    "    for _ in range(epoch):\n",
    "        # initialize the iterator on the training data\n",
    "        sess.run(training_init_op_orig)\n",
    "        # low amount of positive images\n",
    "        # get each element of the training dataset until the end is reached\n",
    "        while True:\n",
    "            try:\n",
    "                (image_batch, ground_truth_batch) = sess.run(next_element_orig)\n",
    "                _, loss_val = sess.run([train_step, cross_entropy],\n",
    "                                       feed_dict={x: image_batch,\n",
    "                                                  y_: ground_truth_batch, keep_prob: 0.5})\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"End of training dataset.\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"error: %s\", e)\n",
    "        train_accuracy = accuracy.eval(feed_dict={ x: image_batch,\n",
    "                                          y_: ground_truth_batch, keep_prob: 1.0})\n",
    "        test_accuracy = accuracy.eval(feed_dict={ x: test_images.values,\n",
    "                                          y_: test_ground_truth.values, keep_prob: 1.0})\n",
    "\n",
    "        num_batches = num_batches + batch_size\n",
    "        print('training accuracy %g' % train_accuracy)\n",
    "        print('test accuracy %g' % test_accuracy)\n",
    "        print('loss_val %g' % loss_val)\n",
    "        train_error_orig.append(1-train_accuracy)\n",
    "        test_error_orig.append(1-test_accuracy)\n",
    "        batch_sizes_orig.append(num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the learning curve\n",
    "\n",
    "What this should tell me is if I'm experience Bias or High variance. You want a low bias network preferably  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.plot(batch_sizes, train_error, 'xb-', marker=\"s\", label='train')\n",
    "ax1.plot(batch_sizes, test_error, 'xr-', marker=\"s\", label='test')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('training size')\n",
    "plt.legend(loc='upper right');\n",
    "plt.title(\"Equal classes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you see belo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOI7jOJ24KDiO4zid/H+QK4lrAG/D9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ce1ba58ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.plot(batch_sizes_orig, train_error_orig, 'xb-', marker=\"s\", label='train')\n",
    "ax1.plot(batch_sizes_orig, test_error_orig, 'xr-', marker=\"s\", label='test')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('training size')\n",
    "plt.title(\"30-70 Split\")\n",
    "plt.legend(loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Looking at the plot what you see is the training error varies quite a lot from zero to 40% to 60% and this is probably caused by the high bias caused by limited positive basket ball images. So when a batch  is "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
